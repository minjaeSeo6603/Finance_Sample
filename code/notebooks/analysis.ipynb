{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debt Attitudes and Household Borrowing Behavior (SCF 2010-2022)\n",
    "\n",
    "**Clean Analysis Notebook**\n",
    "\n",
    "This notebook performs all descriptive and regression analysis for the\n",
    "writing sample paper. It loads the cleaned dataset produced by\n",
    "`data_cleaning.py` and generates figures and tables used in the paper.\n",
    "\n",
    "**Pipeline order:**\n",
    "1. `data_cleaning.py` — produces `cleaned_scf_data.csv`\n",
    "2. This notebook — runs analysis and saves outputs\n",
    "3. `generate_paper_figures.py` — creates publication-quality figures\n",
    "4. `SeoMinjae_Writing_Sample.qmd` — renders the PDF paper"
   ],
   "id": "35539d55"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ],
   "id": "fbb56226"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# --------------- Locate project root ---------------\n",
    "PROJECT_ROOT = None\n",
    "for p in [Path.cwd(), *Path.cwd().parents]:\n",
    "    if (p / \"output\").exists() and (p / \"code\").exists() and (p / \"data\").exists():\n",
    "        PROJECT_ROOT = p\n",
    "        break\n",
    "if PROJECT_ROOT is None:\n",
    "    raise FileNotFoundError(\"Could not locate project root (expected output/, code/, data/ dirs).\")\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"clean\" / \"cleaned_scf_data.csv\"\n",
    "FIGURES_DIR = PROJECT_ROOT / \"output\" / \"figures\"\n",
    "TABLES_DIR = PROJECT_ROOT / \"output\" / \"tables\"\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TABLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --------------- Load cleaned dataset ---------------\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Cleaned data not found at {DATA_PATH}.\\n\"\n",
    "        \"Run data_cleaning.py first:  python code/python/data_cleaning.py\"\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Loaded: {len(df):,} observations, {len(df.columns)} variables\")\n",
    "print(f\"Years: {sorted(df['YEAR'].unique())}\")\n",
    "print(f\"Unique households: {df['YY1'].nunique():,}\")\n",
    "\n",
    "# --------------- Plot settings ---------------\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (12, 6),\n",
    "    \"font.size\": 11,\n",
    "    \"figure.dpi\": 120,\n",
    "    \"savefig.dpi\": 300,\n",
    "})\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "pd.set_option(\"display.width\", 200)"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "61fbb575"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variable Definitions\n",
    "\n",
    "### Debt-Attitude Variables (from SCF Supplementary Module)\n",
    "\n",
    "| Variable | Question | Scale | Interpretation |\n",
    "|----------|----------|-------|----------------|\n",
    "| `X401` | Is borrowing to buy goods when income is cut a good or bad idea? | 1-5 | 1 = Good idea, 5 = Bad idea |\n",
    "| `X402` | Is borrowing for a vacation OK? | 1, 5 | 1 = OK, 5 = Not OK |\n",
    "| `X403` | Is borrowing for living expenses when income is cut OK? | 1, 5 | 1 = OK, 5 = Not OK |\n",
    "| `X405` | Is borrowing to buy a car OK? | 1, 5 | 1 = OK, 5 = Not OK |\n",
    "\n",
    "### Key Outcome and Control Variables\n",
    "\n",
    "| Variable | Description |\n",
    "|----------|-------------|\n",
    "| `DEBT_ADJ` | Total household debt (2022 dollars) |\n",
    "| `LOG_DEBT` | Log-transformed debt: log(1 + DEBT) |\n",
    "| `INCOME_ADJ` | Total household income (2022 dollars) |\n",
    "| `LOG_INCOME_ADJ` | Log-transformed income: log(1 + INCOME_ADJ) |\n",
    "| `NETWORTH` | Household net worth (nominal) |\n",
    "| `LOG_NETWORTH` | IHS-transformed net worth: arcsinh(NETWORTH) |\n",
    "| `DEBT2INC` | Debt-to-income ratio |\n",
    "| `AGE` | Age of household head |\n",
    "| `EDUC` | Years of education |\n",
    "| `EDCL` | Education category (1-4): 1=No HS, 2=HS, 3=Some college, 4=College+ |\n",
    "| `COLLEGE` | Binary: 1 if EDCL >= 4 (bachelor's degree or higher) |\n",
    "| `YOUNG` | Binary: 1 if AGE < 40 |\n",
    "| `WGT` | SCF survey weight |"
   ],
   "id": "a5a00306"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Verify key variables exist in the cleaned data\n",
    "key_vars = [\n",
    "    'X401', 'X402', 'X403', 'X405',\n",
    "    'DEBT', 'DEBT_ADJ', 'LOG_DEBT', 'DEBT2INC',\n",
    "    'INCOME', 'INCOME_ADJ', 'LOG_INCOME_ADJ',\n",
    "    'NETWORTH', 'LOG_NETWORTH',\n",
    "    'AGE', 'EDUC', 'EDCL', 'COLLEGE', 'YOUNG',\n",
    "    'WGT', 'WGT_NORM', 'WGT_SCALED',\n",
    "]\n",
    "for var in key_vars:\n",
    "    status = \"present\" if var in df.columns else \"MISSING\"\n",
    "    print(f\"  {var:<20s} {status}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "6852324a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary Statistics"
   ],
   "id": "cacc37f6"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Financial and demographic summary\n",
    "summary_vars = ['INCOME_ADJ', 'NETWORTH', 'DEBT_ADJ', 'DEBT2INC', 'AGE', 'EDUC']\n",
    "print(\"Summary Statistics (Unweighted)\")\n",
    "print(\"=\" * 70)\n",
    "print(df[summary_vars].describe().round(2))\n",
    "\n",
    "print(\"\\nMedian Values by Year:\")\n",
    "print(df.groupby('YEAR')[summary_vars].median().round(2))"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "cf423eed"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Opinion variable distributions\n",
    "for var, label in [('X401', 'General debt attitude'),\n",
    "                   ('X402', 'Vacation borrowing'),\n",
    "                   ('X403', 'Living-expense borrowing'),\n",
    "                   ('X405', 'Car borrowing')]:\n",
    "    print(f\"\\n{var} - {label}:\")\n",
    "    print(df[var].value_counts().sort_index())"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "16a3af4d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Survey Weights\n",
    "\n",
    "The SCF oversamples wealthier households. All population-level statistics\n",
    "use SCF survey weights (`WGT`). Weights were normalized within each year\n",
    "during data cleaning."
   ],
   "id": "7cd54c8d"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "weight_summary = df.groupby('YEAR')['WGT'].agg(\n",
    "    Sum='sum', Mean='mean', Median='median', Std='std', Min='min', Max='max'\n",
    ")\n",
    "print(\"Weight Summary by Year:\")\n",
    "print(weight_summary.round(2))"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "064719f4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Weighted Trends in Debt Attitudes (X401)\n",
    "\n",
    "We group X401 into three categories:\n",
    "- **Good idea** (X401 <= 2): Favorable toward borrowing\n",
    "- **Mixed** (X401 = 3): Neutral\n",
    "- **Bad idea** (X401 >= 4): Unfavorable toward borrowing"
   ],
   "id": "5cf1ade3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compute weighted shares by attitude group and year\n",
    "def classify_x401(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    if x <= 2: return 'Good idea'\n",
    "    if x == 3: return 'Mixed'\n",
    "    return 'Bad idea'\n",
    "\n",
    "df['X401_GROUP'] = df['X401'].apply(classify_x401)\n",
    "\n",
    "shares = (\n",
    "    df.dropna(subset=['X401_GROUP'])\n",
    "    .groupby(['YEAR', 'X401_GROUP'], as_index=False)['WGT']\n",
    "    .sum()\n",
    "    .rename(columns={'WGT': 'wgt_sum'})\n",
    ")\n",
    "shares['pct'] = shares['wgt_sum'] / shares.groupby('YEAR')['wgt_sum'].transform('sum') * 100\n",
    "\n",
    "group_order = ['Good idea', 'Mixed', 'Bad idea']\n",
    "shares['X401_GROUP'] = pd.Categorical(shares['X401_GROUP'], categories=group_order, ordered=True)\n",
    "pivot = shares.pivot(index='X401_GROUP', columns='YEAR', values='pct').reindex(group_order)\n",
    "\n",
    "print(\"Weighted Attitude Distribution (%)\")\n",
    "print(\"=\" * 55)\n",
    "print(pivot.round(1))\n",
    "print()\n",
    "for grp in group_order:\n",
    "    change = pivot.loc[grp, 2022] - pivot.loc[grp, 2010]\n",
    "    print(f\"  {grp}: {change:+.1f} pp from 2010 to 2022\")\n",
    "\n",
    "# Save for paper reference\n",
    "att_table = shares.pivot(index='YEAR', columns='X401_GROUP', values='pct').reindex(columns=group_order)\n",
    "att_table.to_csv(TABLES_DIR / 'x401_attitude_groups_by_year.csv')"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "d3a48f0c"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# X401 weighted trend plot\n",
    "weighted_mean = (\n",
    "    df.dropna(subset=['X401'])\n",
    "    .groupby('YEAR')\n",
    "    .apply(lambda g: np.average(g['X401'], weights=g['WGT']))\n",
    "    .reset_index(name='mean_x401')\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5.5))\n",
    "\n",
    "# Left: stacked shares\n",
    "for grp, color in zip(group_order, ['#2E86AB', '#F6AE2D', '#F18F01']):\n",
    "    g = shares[shares['X401_GROUP'] == grp].sort_values('YEAR')\n",
    "    axes[0].plot(g['YEAR'], g['pct'], marker='o', linewidth=2.5, color=color, label=grp)\n",
    "axes[0].set_title('Weighted Attitude Shares by Year')\n",
    "axes[0].set_ylabel('Share (%)')\n",
    "axes[0].set_xticks([2010, 2016, 2022])\n",
    "axes[0].legend(loc='center right')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Right: weighted mean X401\n",
    "axes[1].plot(weighted_mean['YEAR'], weighted_mean['mean_x401'],\n",
    "             marker='s', linewidth=2.5, color='#A23B72')\n",
    "axes[1].set_title('Weighted Mean X401 (Lower = More Debt-Friendly)')\n",
    "axes[1].set_ylabel('Mean X401')\n",
    "axes[1].set_xticks([2010, 2016, 2022])\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / 'x401_weighted_trend.png', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "e4cff7ab"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Demographic Heterogeneity\n",
    "\n",
    "Compare debt-friendly attitudes (X401 <= 2) across age and education\n",
    "groups. `YOUNG` (age < 40) and `COLLEGE` (EDCL >= 4, i.e. bachelor's\n",
    "degree or higher) come from the cleaned data."
   ],
   "id": "621c46b0"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ensure interaction variable exists\n",
    "if 'YOUNG_COLLEGE' not in df.columns:\n",
    "    df['YOUNG_COLLEGE'] = df['YOUNG'] * df['COLLEGE']\n",
    "\n",
    "def favorable_pct(subset):\n",
    "    \"\"\"Weighted share with X401 <= 2.\"\"\"\n",
    "    fav = subset[subset['X401'] <= 2]['WGT'].sum()\n",
    "    total = subset['WGT'].sum()\n",
    "    return (fav / total * 100) if total > 0 else 0\n",
    "\n",
    "rows = []\n",
    "for year in [2010, 2016, 2022]:\n",
    "    y = df[df['YEAR'] == year]\n",
    "    rows.append({\n",
    "        'Year': year,\n",
    "        'Young (<40)': favorable_pct(y[y['YOUNG'] == 1]),\n",
    "        'Older (40+)':  favorable_pct(y[y['YOUNG'] == 0]),\n",
    "        'College+':     favorable_pct(y[y['COLLEGE'] == 1]),\n",
    "        'No College':   favorable_pct(y[y['COLLEGE'] == 0]),\n",
    "    })\n",
    "trends = pd.DataFrame(rows)\n",
    "\n",
    "print(\"Debt-friendly share (X401 <= 2) by demographic group\")\n",
    "print(\"=\" * 70)\n",
    "print(trends.round(1))"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "cdcbbcfa"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Demographic trend plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# By Age\n",
    "for grp, col, marker in [('Young (<40)', '#2E86AB', 'o'), ('Older (40+)', '#A23B72', 's')]:\n",
    "    axes[0].plot(trends['Year'], trends[grp], marker=marker, linewidth=2.5, color=col, label=grp)\n",
    "axes[0].set_title('Debt-Favorable Attitudes by Age Group')\n",
    "axes[0].set_ylabel('Share with X401 <= 2 (%)')\n",
    "axes[0].set_xticks([2010, 2016, 2022])\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# By Education\n",
    "for grp, col, marker in [('College+', '#2E86AB', 'o'), ('No College', '#A23B72', 's')]:\n",
    "    axes[1].plot(trends['Year'], trends[grp], marker=marker, linewidth=2.5, color=col, label=grp)\n",
    "axes[1].set_title('Debt-Favorable Attitudes by Education')\n",
    "axes[1].set_ylabel('Share with X401 <= 2 (%)')\n",
    "axes[1].set_xticks([2010, 2016, 2022])\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "1e333fbc"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Purpose-Specific Borrowing Acceptance\n",
    "\n",
    "For X402, X403, X405, acceptance is defined as response <= 2.\n",
    "This reveals whether households distinguish necessity-linked from\n",
    "discretionary debt."
   ],
   "id": "f1b8da9b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def acceptance_rate(subset, var):\n",
    "    accepted = subset[subset[var] <= 2]['WGT'].sum()\n",
    "    total = subset['WGT'].sum()\n",
    "    return (accepted / total * 100) if total > 0 else 0\n",
    "\n",
    "rows = []\n",
    "for year in [2010, 2016, 2022]:\n",
    "    y = df[df['YEAR'] == year]\n",
    "    rows.append({\n",
    "        'Year': year,\n",
    "        'Vacation (X402)':         acceptance_rate(y, 'X402'),\n",
    "        'Living Expenses (X403)':  acceptance_rate(y, 'X403'),\n",
    "        'Car (X405)':              acceptance_rate(y, 'X405'),\n",
    "    })\n",
    "accept = pd.DataFrame(rows)\n",
    "\n",
    "print(\"Acceptance Rates by Borrowing Purpose (weighted, X <= 2)\")\n",
    "print(\"=\" * 60)\n",
    "print(accept.round(1))\n",
    "\n",
    "# Save for generate_paper_figures.py\n",
    "purpose_long = []\n",
    "purpose_map = {\n",
    "    'Vacation (X402)': ('X402', 'Vacation (Luxury)'),\n",
    "    'Living Expenses (X403)': ('X403', 'Living expenses (Necessity)'),\n",
    "    'Car (X405)': ('X405', 'Car purchase (Durable/necessary)'),\n",
    "}\n",
    "for year in [2010, 2016, 2022]:\n",
    "    y = df[df['YEAR'] == year]\n",
    "    for col, (var, label) in purpose_map.items():\n",
    "        purpose_long.append({\n",
    "            'YEAR': year,\n",
    "            'variable': var,\n",
    "            'label': label,\n",
    "            'acceptance_rate': acceptance_rate(y, var) / 100,\n",
    "        })\n",
    "pd.DataFrame(purpose_long).to_csv(TABLES_DIR / 'purpose_acceptance_by_year.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "0353bae6"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Purpose acceptance bar chart\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "x = np.arange(3)\n",
    "width = 0.25\n",
    "purposes = ['Vacation (X402)', 'Living Expenses (X403)', 'Car (X405)']\n",
    "colors = ['#F18F01', '#A23B72', '#2E86AB']\n",
    "\n",
    "for i, year in enumerate([2010, 2016, 2022]):\n",
    "    vals = [accept.loc[accept['Year'] == year, p].values[0] for p in purposes]\n",
    "    ax.bar(x + i * width, vals, width=width, color=colors[i], label=str(year), alpha=0.9)\n",
    "\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(['Vacation', 'Living Expenses', 'Car'])\n",
    "ax.set_ylabel('Acceptance Rate (%)')\n",
    "ax.set_title('Purpose-Specific Debt Acceptance by Year')\n",
    "ax.legend(title='Year')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "25668711"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Quality Checks"
   ],
   "id": "75720ecb"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "print(\"Missing Data Summary\")\n",
    "print(\"=\" * 60)\n",
    "missing = (df.isnull().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "missing = missing[missing > 0]\n",
    "if len(missing) > 0:\n",
    "    print(f\"Variables with missing data: {len(missing)}\")\n",
    "    print(missing.head(10).round(2))\n",
    "else:\n",
    "    print(\"No missing data detected.\")\n",
    "\n",
    "# Integrity\n",
    "print(\"\\nData Integrity\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total observations: {len(df):,}\")\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Unique households: {df['YY1'].nunique():,}\")\n",
    "print(f\"\\nImplicates per household:\")\n",
    "print(df.groupby(['YEAR', 'YY1']).size().value_counts())\n",
    "print(f\"\\nObservations by year:\")\n",
    "for year, count in df.groupby('YEAR').size().items():\n",
    "    print(f\"  {int(year)}: {count:,} ({count/len(df)*100:.1f}%)\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "2f20c6e2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Baseline Regressions\n",
    "\n",
    "Two benchmark models:\n",
    "1. **Model 1 (Attitude):** What predicts debt attitudes (X401)?\n",
    "2. **Model 2 (Behavior):** Do attitudes predict actual debt (LOG_DEBT)?\n",
    "\n",
    "All models use WLS with SCF survey weights and household-cluster\n",
    "robust standard errors."
   ],
   "id": "8007587f"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Regression helper functions\n",
    "def fit_wls(data, formula, weight_col='WGT_SCALED', cluster_col='HH_CLUSTER'):\n",
    "    \"\"\"Fit WLS with cluster-robust standard errors.\"\"\"\n",
    "    return smf.wls(formula, data=data, weights=data[weight_col]).fit(\n",
    "        cov_type='cluster', cov_kwds={'groups': data[cluster_col]}\n",
    "    )\n",
    "\n",
    "def tidy(model, model_name):\n",
    "    \"\"\"Extract a tidy coefficient table from a fitted model.\"\"\"\n",
    "    out = pd.DataFrame({\n",
    "        'term': model.params.index,\n",
    "        'coef': model.params.values,\n",
    "        'std_err': model.bse.values,\n",
    "        'p_value': model.pvalues.values,\n",
    "    })\n",
    "    out['stars'] = np.select(\n",
    "        [out['p_value'] < 0.01, out['p_value'] < 0.05, out['p_value'] < 0.10],\n",
    "        ['***', '**', '*'], default=''\n",
    "    )\n",
    "    out['coef_se'] = out.apply(\n",
    "        lambda r: f\"{r['coef']:.4f}{r['stars']} ({r['std_err']:.4f})\", axis=1\n",
    "    )\n",
    "    out['model'] = model_name\n",
    "    return out\n",
    "\n",
    "# --------------- Prepare regression data ---------------\n",
    "reg = df.copy()\n",
    "\n",
    "# Ensure cluster ID for robust SEs\n",
    "reg['HH_CLUSTER'] = reg['YEAR'].astype(str) + '_' + reg['YY1'].astype(str)\n",
    "\n",
    "# Ensure WGT_SCALED exists (mean=1 within each year)\n",
    "if 'WGT_SCALED' not in reg.columns:\n",
    "    reg['WGT_SCALED'] = reg.groupby('YEAR')['WGT'].transform(lambda x: x / x.mean())\n",
    "\n",
    "# --------------- Model 1: Determinants of X401 ---------------\n",
    "m1_data = reg[['X401','YEAR','LOG_INCOME_ADJ','AGE','EDUC','LOG_NETWORTH',\n",
    "               'DEBT2INC','WGT_SCALED','HH_CLUSTER']].dropna()\n",
    "m1_data = m1_data[m1_data['X401'].between(1, 5)]\n",
    "\n",
    "model1 = fit_wls(m1_data,\n",
    "    'X401 ~ C(YEAR) + LOG_INCOME_ADJ + AGE + EDUC + LOG_NETWORTH + DEBT2INC')\n",
    "\n",
    "t1 = tidy(model1, 'X401_main')\n",
    "t1.to_csv(TABLES_DIR / 'reg_model1_x401_determinants.csv', index=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL 1: Determinants of Debt Attitude (X401)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"N = {len(m1_data):,},  R-sq = {model1.rsquared:.4f}\")\n",
    "print(t1[['term', 'coef_se', 'p_value']].to_string(index=False))\n",
    "\n",
    "y16 = model1.params.get('C(YEAR)[T.2016]', np.nan)\n",
    "y22 = model1.params.get('C(YEAR)[T.2022]', np.nan)\n",
    "print(f\"\\nYear 2016 vs 2010: {y16:.4f} (negative = more debt-friendly)\")\n",
    "print(f\"Year 2022 vs 2010: {y22:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "2a34f6fd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Behavioral Consistency: Do Attitudes Predict Actual Debt?\n",
    "\n",
    "Regress log real debt on X401 with controls. A negative coefficient means\n",
    "more debt-friendly attitudes (lower X401) are associated with higher debt."
   ],
   "id": "0b133098"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --------------- Model 2: LOG_DEBT on attitudes ---------------\n",
    "m2_data = reg[['LOG_DEBT','DEBT_ADJ','X401','YEAR','LOG_INCOME_ADJ',\n",
    "               'AGE','EDUC','LOG_NETWORTH','WGT_SCALED','HH_CLUSTER']].dropna()\n",
    "m2_data = m2_data[m2_data['X401'].between(1, 5)]\n",
    "\n",
    "model2 = fit_wls(m2_data,\n",
    "    'LOG_DEBT ~ X401 + C(YEAR) + LOG_INCOME_ADJ + AGE + EDUC + LOG_NETWORTH')\n",
    "\n",
    "t2 = tidy(model2, 'Debt_behavior')\n",
    "t2.to_csv(TABLES_DIR / 'reg_model2_logdebt_behavior.csv', index=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL 2: Real Debt Holdings on Attitude (LOG_DEBT)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"N = {len(m2_data):,},  R-sq = {model2.rsquared:.4f}\")\n",
    "print(t2[['term', 'coef_se', 'p_value']].to_string(index=False))\n",
    "\n",
    "att_coef = model2.params['X401']\n",
    "print(f\"\\nOne-point increase in X401 -> {100*(np.exp(att_coef)-1):.1f}% change in debt\")\n",
    "print(f\"Move X401=1 to X401=5 -> {100*(np.exp(att_coef*4)-1):.1f}% change in debt\")\n",
    "\n",
    "# Weighted debt by attitude category (for bar chart)\n",
    "debt_by_att = (\n",
    "    m2_data.groupby('X401')\n",
    "    .apply(lambda g: np.average(g['DEBT_ADJ'], weights=g['WGT_SCALED']))\n",
    "    .reset_index(name='avg_debt')\n",
    "    .sort_values('X401')\n",
    ")\n",
    "\n",
    "label_map = {1:'Good idea (1)', 2:'Mostly good (2)', 3:'Mixed (3)',\n",
    "             4:'Mostly bad (4)', 5:'Bad idea (5)'}\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(\n",
    "    [label_map[int(x)] for x in debt_by_att['X401']],\n",
    "    debt_by_att['avg_debt'] / 1000,\n",
    "    color=['#2E86AB','#4D9EC5','#A23B72','#D97D3E','#F18F01'],\n",
    "    edgecolor='black', linewidth=1, alpha=0.9,\n",
    ")\n",
    "for bar, val in zip(bars, debt_by_att['avg_debt'] / 1000):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height()+1.2,\n",
    "            f'{val:,.0f}', ha='center', fontsize=10)\n",
    "ax.set_ylabel('Average Real Debt (2022 $1,000)')\n",
    "ax.set_title('Weighted Debt Holdings by Attitude Category')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / 'debt_by_attitude_refined.png', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "6d07fa08"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Heterogeneity: Age and Education Interactions\n",
    "\n",
    "**Model 3:** Interact year dummies with YOUNG and COLLEGE to test whether\n",
    "attitude shifts differ across demographic groups.\n",
    "\n",
    "**Model 4:** Purpose-specific linear probability models (acceptance = X <= 2)."
   ],
   "id": "e433fe62"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --------------- Model 3: Heterogeneous year effects ---------------\n",
    "m3_data = reg[['X401','YEAR','YOUNG','COLLEGE','LOG_INCOME_ADJ','AGE','EDUC',\n",
    "               'LOG_NETWORTH','DEBT2INC','WGT_SCALED','HH_CLUSTER',\n",
    "               'X402','X403','X405']].dropna()\n",
    "m3_data = m3_data[m3_data['X401'].between(1, 5)]\n",
    "\n",
    "model3 = fit_wls(m3_data,\n",
    "    'X401 ~ C(YEAR) * YOUNG + C(YEAR) * COLLEGE + '\n",
    "    'LOG_INCOME_ADJ + AGE + EDUC + LOG_NETWORTH + DEBT2INC')\n",
    "\n",
    "t3 = tidy(model3, 'Heterogeneity_joint')\n",
    "t3.to_csv(TABLES_DIR / 'reg_model3_heterogeneity.csv', index=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL 3: Heterogeneous Year Effects (Age + Education)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"N = {len(m3_data):,},  R-sq = {model3.rsquared:.4f}\")\n",
    "key_terms = [t for t in model3.params.index if 'YOUNG' in t or 'COLLEGE' in t or 'YEAR' in t]\n",
    "print(t3[t3['term'].isin(key_terms)][['term','coef_se','p_value']].to_string(index=False))\n",
    "\n",
    "# --------------- Model 4: Purpose-specific acceptance ---------------\n",
    "for v in ['X402', 'X403', 'X405']:\n",
    "    m3_data[f'{v}_BIN'] = np.where(m3_data[v].between(1,5), (m3_data[v]<=2).astype(float), np.nan)\n",
    "\n",
    "purpose_models = {\n",
    "    'X402_BIN': 'Vacation acceptance',\n",
    "    'X403_BIN': 'Living-expense acceptance',\n",
    "    'X405_BIN': 'Car-loan acceptance',\n",
    "}\n",
    "\n",
    "purpose_results = []\n",
    "for outcome, label in purpose_models.items():\n",
    "    tmp = m3_data[[outcome,'X401','YEAR','LOG_INCOME_ADJ','AGE','EDUC',\n",
    "                    'LOG_NETWORTH','DEBT2INC','WGT_SCALED','HH_CLUSTER']].dropna()\n",
    "    m = fit_wls(tmp,\n",
    "        f'{outcome} ~ X401 + C(YEAR) + LOG_INCOME_ADJ + AGE + EDUC + LOG_NETWORTH + DEBT2INC')\n",
    "    t = tidy(m, label)\n",
    "    t['outcome'] = outcome\n",
    "    t['n_obs'] = len(tmp)\n",
    "    t['r2'] = m.rsquared\n",
    "    purpose_results.append(t)\n",
    "\n",
    "purpose_table = pd.concat(purpose_results, ignore_index=True)\n",
    "purpose_table.to_csv(TABLES_DIR / 'reg_model4_purpose_specific.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL 4: Purpose-Specific Acceptance (LPM)\")\n",
    "print(\"=\" * 80)\n",
    "focus = ['X401', 'C(YEAR)[T.2016]', 'C(YEAR)[T.2022]']\n",
    "for outcome, label in purpose_models.items():\n",
    "    sub = purpose_table[(purpose_table['outcome']==outcome) & purpose_table['term'].isin(focus)]\n",
    "    r2 = purpose_table.loc[purpose_table['outcome']==outcome, 'r2'].iloc[0]\n",
    "    n = int(purpose_table.loc[purpose_table['outcome']==outcome, 'n_obs'].iloc[0])\n",
    "    print(f\"\\n{label} | N={n:,}, R-sq={r2:.4f}\")\n",
    "    print(sub[['term','coef_se','p_value']].to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "5532f54b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Combined Tables for Paper Figures\n",
    "\n",
    "Create `regression_main_models.csv` and `regression_heterogeneity.csv`\n",
    "used by `generate_paper_figures.py`.\n"
   ],
   "id": "6f91ad28"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Combine Model 1 and Model 2 into the format expected by generate_paper_figures.py\n",
    "m1_out = pd.DataFrame({\n",
    "    'model': 'X401_main',\n",
    "    'term': model1.params.index,\n",
    "    'coef': model1.params.values,\n",
    "    'std_err': model1.bse.values,\n",
    "    'p_value': model1.pvalues.values,\n",
    "    'n_obs': len(m1_data),\n",
    "    'r_squared': model1.rsquared,\n",
    "})\n",
    "\n",
    "m2_out = pd.DataFrame({\n",
    "    'model': 'Debt_behavior',\n",
    "    'term': model2.params.index,\n",
    "    'coef': model2.params.values,\n",
    "    'std_err': model2.bse.values,\n",
    "    'p_value': model2.pvalues.values,\n",
    "    'n_obs': len(m2_data),\n",
    "    'r_squared': model2.rsquared,\n",
    "})\n",
    "\n",
    "main_table = pd.concat([m1_out, m2_out], ignore_index=True)\n",
    "main_table.to_csv(TABLES_DIR / 'regression_main_models.csv', index=False)\n",
    "\n",
    "# Heterogeneity table\n",
    "het_out = pd.DataFrame({\n",
    "    'model': 'Heterogeneity_joint',\n",
    "    'term': model3.params.index,\n",
    "    'coef': model3.params.values,\n",
    "    'std_err': model3.bse.values,\n",
    "    'p_value': model3.pvalues.values,\n",
    "    'n_obs': len(m3_data),\n",
    "    'r_squared': model3.rsquared,\n",
    "})\n",
    "het_out.to_csv(TABLES_DIR / 'regression_heterogeneity.csv', index=False)\n",
    "\n",
    "print(\"Saved combined tables:\")\n",
    "print(f\"  - {TABLES_DIR / 'regression_main_models.csv'}\")\n",
    "print(f\"  - {TABLES_DIR / 'regression_heterogeneity.csv'}\")\n",
    "print(f\"\\nregression_main_models.csv terms for X401_main:\")\n",
    "print(main_table[main_table['model']=='X401_main'][['term','coef','std_err']].to_string(index=False))"
   ],
   "outputs": [],
   "execution_count": null,
   "id": "830c3e0f"
  }
 ]
}
